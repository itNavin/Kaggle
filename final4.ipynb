{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1575c0cc",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-11-21T15:20:44.432345Z",
     "iopub.status.busy": "2024-11-21T15:20:44.431866Z",
     "iopub.status.idle": "2024-11-21T15:20:45.449807Z",
     "shell.execute_reply": "2024-11-21T15:20:45.448540Z"
    },
    "papermill": {
     "duration": 1.025093,
     "end_time": "2024-11-21T15:20:45.452614",
     "exception": false,
     "start_time": "2024-11-21T15:20:44.427521",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/store-sales-time-series-forecasting/oil.csv\n",
      "/kaggle/input/store-sales-time-series-forecasting/sample_submission.csv\n",
      "/kaggle/input/store-sales-time-series-forecasting/holidays_events.csv\n",
      "/kaggle/input/store-sales-time-series-forecasting/stores.csv\n",
      "/kaggle/input/store-sales-time-series-forecasting/train.csv\n",
      "/kaggle/input/store-sales-time-series-forecasting/test.csv\n",
      "/kaggle/input/store-sales-time-series-forecasting/transactions.csv\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "27033805",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-21T15:20:45.460543Z",
     "iopub.status.busy": "2024-11-21T15:20:45.460019Z",
     "iopub.status.idle": "2024-11-21T15:21:27.386752Z",
     "shell.execute_reply": "2024-11-21T15:21:27.385127Z"
    },
    "papermill": {
     "duration": 41.938954,
     "end_time": "2024-11-21T15:21:27.394047",
     "exception": false,
     "start_time": "2024-11-21T15:20:45.455093",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_17/934618069.py:37: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  oil_data['dcoilwtico'].fillna(method='ffill', inplace=True)  # Forward fill\n",
      "/tmp/ipykernel_17/934618069.py:37: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  oil_data['dcoilwtico'].fillna(method='ffill', inplace=True)  # Forward fill\n",
      "/tmp/ipykernel_17/934618069.py:38: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  oil_data['dcoilwtico'].fillna(method='bfill', inplace=True)  # Backward fill (if needed)\n",
      "/tmp/ipykernel_17/934618069.py:38: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  oil_data['dcoilwtico'].fillna(method='bfill', inplace=True)  # Backward fill (if needed)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns with missing values:\n",
      "sales          28512\n",
      "dcoilwtico    885654\n",
      "dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_17/934618069.py:92: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  final_encoded_data['dcoilwtico'].fillna(method='ffill', inplace=True)  # Forward fill\n",
      "/tmp/ipykernel_17/934618069.py:92: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  final_encoded_data['dcoilwtico'].fillna(method='ffill', inplace=True)  # Forward fill\n",
      "/tmp/ipykernel_17/934618069.py:93: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  final_encoded_data['dcoilwtico'].fillna(method='bfill', inplace=True)  # Backward fill (if needed)\n",
      "/tmp/ipykernel_17/934618069.py:93: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  final_encoded_data['dcoilwtico'].fillna(method='bfill', inplace=True)  # Backward fill (if needed)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated DataFrame after encoding and dropping 'date':\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>store_nbr</th>\n",
       "      <th>sales</th>\n",
       "      <th>onpromotion</th>\n",
       "      <th>dcoilwtico</th>\n",
       "      <th>type_Additional</th>\n",
       "      <th>type_Bridge</th>\n",
       "      <th>type_Event</th>\n",
       "      <th>type_Holiday</th>\n",
       "      <th>type_Transfer</th>\n",
       "      <th>...</th>\n",
       "      <th>family_POULTRY</th>\n",
       "      <th>family_PREPARED FOODS</th>\n",
       "      <th>family_PRODUCE</th>\n",
       "      <th>family_SCHOOL AND OFFICE SUPPLIES</th>\n",
       "      <th>family_SEAFOOD</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>is_weekend</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>93.14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>93.14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>93.14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>93.14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>93.14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3082855</th>\n",
       "      <td>3029395</td>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>47.26</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2017</td>\n",
       "      <td>8</td>\n",
       "      <td>31</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3082856</th>\n",
       "      <td>3029396</td>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>47.26</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2017</td>\n",
       "      <td>8</td>\n",
       "      <td>31</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3082857</th>\n",
       "      <td>3029397</td>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>47.26</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2017</td>\n",
       "      <td>8</td>\n",
       "      <td>31</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3082858</th>\n",
       "      <td>3029398</td>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9</td>\n",
       "      <td>47.26</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2017</td>\n",
       "      <td>8</td>\n",
       "      <td>31</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3082859</th>\n",
       "      <td>3029399</td>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>47.26</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2017</td>\n",
       "      <td>8</td>\n",
       "      <td>31</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3029400 rows × 54 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              id  store_nbr  sales  onpromotion  dcoilwtico  type_Additional  \\\n",
       "0              0          1    0.0            0       93.14                0   \n",
       "1              1          1    0.0            0       93.14                0   \n",
       "2              2          1    0.0            0       93.14                0   \n",
       "3              3          1    0.0            0       93.14                0   \n",
       "4              4          1    0.0            0       93.14                0   \n",
       "...          ...        ...    ...          ...         ...              ...   \n",
       "3082855  3029395          9    NaN            1       47.26                0   \n",
       "3082856  3029396          9    NaN            0       47.26                0   \n",
       "3082857  3029397          9    NaN            1       47.26                0   \n",
       "3082858  3029398          9    NaN            9       47.26                0   \n",
       "3082859  3029399          9    NaN            0       47.26                0   \n",
       "\n",
       "         type_Bridge  type_Event  type_Holiday  type_Transfer  ...  \\\n",
       "0                  0           0             1              0  ...   \n",
       "1                  0           0             1              0  ...   \n",
       "2                  0           0             1              0  ...   \n",
       "3                  0           0             1              0  ...   \n",
       "4                  0           0             1              0  ...   \n",
       "...              ...         ...           ...            ...  ...   \n",
       "3082855            0           0             0              0  ...   \n",
       "3082856            0           0             0              0  ...   \n",
       "3082857            0           0             0              0  ...   \n",
       "3082858            0           0             0              0  ...   \n",
       "3082859            0           0             0              0  ...   \n",
       "\n",
       "         family_POULTRY  family_PREPARED FOODS  family_PRODUCE  \\\n",
       "0                     0                      0               0   \n",
       "1                     0                      0               0   \n",
       "2                     0                      0               0   \n",
       "3                     0                      0               0   \n",
       "4                     0                      0               0   \n",
       "...                 ...                    ...             ...   \n",
       "3082855               1                      0               0   \n",
       "3082856               0                      1               0   \n",
       "3082857               0                      0               1   \n",
       "3082858               0                      0               0   \n",
       "3082859               0                      0               0   \n",
       "\n",
       "         family_SCHOOL AND OFFICE SUPPLIES  family_SEAFOOD  year  month  day  \\\n",
       "0                                        0               0  2013      1    1   \n",
       "1                                        0               0  2013      1    1   \n",
       "2                                        0               0  2013      1    1   \n",
       "3                                        0               0  2013      1    1   \n",
       "4                                        0               0  2013      1    1   \n",
       "...                                    ...             ...   ...    ...  ...   \n",
       "3082855                                  0               0  2017      8   31   \n",
       "3082856                                  0               0  2017      8   31   \n",
       "3082857                                  0               0  2017      8   31   \n",
       "3082858                                  1               0  2017      8   31   \n",
       "3082859                                  0               1  2017      8   31   \n",
       "\n",
       "         day_of_week  is_weekend  \n",
       "0                  1           0  \n",
       "1                  1           0  \n",
       "2                  1           0  \n",
       "3                  1           0  \n",
       "4                  1           0  \n",
       "...              ...         ...  \n",
       "3082855            3           0  \n",
       "3082856            3           0  \n",
       "3082857            3           0  \n",
       "3082858            3           0  \n",
       "3082859            3           0  \n",
       "\n",
       "[3029400 rows x 54 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation MAE: 102.50700245111082\n",
      "Submission file preview:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_17/934618069.py:163: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_data['sales'] = model.predict(X_test)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3000888</td>\n",
       "      <td>-14.345853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3000889</td>\n",
       "      <td>-9.103026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3000890</td>\n",
       "      <td>-37.323532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3000891</td>\n",
       "      <td>2605.227539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3000892</td>\n",
       "      <td>-22.602394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28507</th>\n",
       "      <td>3029395</td>\n",
       "      <td>376.531128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28508</th>\n",
       "      <td>3029396</td>\n",
       "      <td>83.442253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28509</th>\n",
       "      <td>3029397</td>\n",
       "      <td>1211.333740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28510</th>\n",
       "      <td>3029398</td>\n",
       "      <td>163.126221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28511</th>\n",
       "      <td>3029399</td>\n",
       "      <td>45.230534</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>28512 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            id        sales\n",
       "0      3000888   -14.345853\n",
       "1      3000889    -9.103026\n",
       "2      3000890   -37.323532\n",
       "3      3000891  2605.227539\n",
       "4      3000892   -22.602394\n",
       "...        ...          ...\n",
       "28507  3029395   376.531128\n",
       "28508  3029396    83.442253\n",
       "28509  3029397  1211.333740\n",
       "28510  3029398   163.126221\n",
       "28511  3029399    45.230534\n",
       "\n",
       "[28512 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "# Load datasets\n",
    "train_data = pd.read_csv('/kaggle/input/store-sales-time-series-forecasting/train.csv')\n",
    "test_data = pd.read_csv('/kaggle/input/store-sales-time-series-forecasting/test.csv')\n",
    "oil_data = pd.read_csv('/kaggle/input/store-sales-time-series-forecasting/oil.csv')\n",
    "holiday_data = pd.read_csv('/kaggle/input/store-sales-time-series-forecasting/holidays_events.csv')\n",
    "sample_submission = pd.read_csv('/kaggle/input/store-sales-time-series-forecasting/sample_submission.csv')\n",
    "\n",
    "# Convert 'date' columns to datetime format\n",
    "train_data['date'] = pd.to_datetime(train_data['date'])\n",
    "test_data['date'] = pd.to_datetime(test_data['date'])\n",
    "oil_data['date'] = pd.to_datetime(oil_data['date'])\n",
    "holiday_data['date'] = pd.to_datetime(holiday_data['date'])\n",
    "#display(train_data) \n",
    "#display(test_data)\n",
    "\n",
    "# Merge the two datasets\n",
    "merged_data = pd.concat([train_data, test_data], ignore_index=True)\n",
    "\n",
    "# Display the merged dataset\n",
    "#print(\"Merged Dataset:\")\n",
    "#display(merged_data)\n",
    "\n",
    "# Check for missing values in the oil_data dataset\n",
    "missing_oil = oil_data['dcoilwtico'].isna().sum()\n",
    "#print(f\"Number of missing values in 'dcoilwtico' column: {missing_oil}\")\n",
    "\n",
    "# Handle missing values in the 'dcoilwtico' column by interpolation\n",
    "oil_data['dcoilwtico'] = oil_data['dcoilwtico'].interpolate(method='linear')\n",
    "\n",
    "# Handle any remaining missing values (e.g., at the start or end) with forward/backward fill\n",
    "oil_data['dcoilwtico'].fillna(method='ffill', inplace=True)  # Forward fill\n",
    "oil_data['dcoilwtico'].fillna(method='bfill', inplace=True)  # Backward fill (if needed)\n",
    "\n",
    "# Verify no missing values remain\n",
    "missing_oil_after = oil_data['dcoilwtico'].isna().sum()\n",
    "#print(f\"Number of missing values in 'dcoilwtico' column after handling all missing values: {missing_oil_after}\")\n",
    "\n",
    "#display(holiday_data)\n",
    "# Drop 'locale_name' and 'description' columns from holiday_data\n",
    "holiday_data.drop(columns=['locale_name', 'description'], inplace=True, errors='ignore')\n",
    "\n",
    "# Display the updated holiday_data to verify\n",
    "#print(\"Updated holiday_data:\")\n",
    "#display(holiday_data)\n",
    "\n",
    "# Merge merged_data with holiday_data on the 'date' column\n",
    "merged_data_with_holiday = pd.merge(merged_data, holiday_data, on='date', how='left')\n",
    "\n",
    "# Display the merged dataset\n",
    "#print(\"Merged Data with Holiday Data:\")\n",
    "#display(merged_data_with_holiday)\n",
    "\n",
    "# Merge merged_data_with_holiday with oil_data on the 'date' column\n",
    "final_merged_data = pd.merge(merged_data_with_holiday, oil_data, on='date', how='left')\n",
    "\n",
    "# Display the merged dataset\n",
    "#print(\"Final Merged Data (with Oil Data):\")\n",
    "#display(final_merged_data)\n",
    "\n",
    "# Select categorical columns for one-hot encoding, including 'family'\n",
    "categorical_columns = ['type', 'locale', 'transferred', 'family'] \n",
    "\n",
    "# Perform one-hot encoding\n",
    "final_encoded_data = pd.get_dummies(final_merged_data, columns=categorical_columns, prefix=categorical_columns, dtype=int)\n",
    "\n",
    "# Display the encoded dataset\n",
    "#print(\"Final Encoded Data:\")\n",
    "#display(final_encoded_data)\n",
    "\n",
    "# Check for NaN values in the dataset\n",
    "missing_values = final_encoded_data.isna().sum()\n",
    "\n",
    "# Display only columns with missing values\n",
    "missing_values = missing_values[missing_values > 0]\n",
    "\n",
    "if missing_values.empty:\n",
    "    print(\"No missing values in the dataset.\")\n",
    "else:\n",
    "    print(\"Columns with missing values:\")\n",
    "    print(missing_values)\n",
    "\n",
    "# Interpolate missing values in the 'dcoilwtico' column using linear interpolation\n",
    "final_encoded_data['dcoilwtico'] = final_encoded_data['dcoilwtico'].interpolate(method='linear')\n",
    "\n",
    "# Fill any remaining missing values at the beginning or end using forward and backward fill\n",
    "final_encoded_data['dcoilwtico'].fillna(method='ffill', inplace=True)  # Forward fill\n",
    "final_encoded_data['dcoilwtico'].fillna(method='bfill', inplace=True)  # Backward fill (if needed)\n",
    "\n",
    "# Verify no missing values remain in 'dcoilwtico'\n",
    "missing_dcoilwtico = final_encoded_data['dcoilwtico'].isna().sum()\n",
    "#print(f\"Remaining missing values in 'dcoilwtico': {missing_dcoilwtico}\")\n",
    "\n",
    "#print(final_encoded_data.isna().sum())\n",
    "\n",
    "# Check for duplicate IDs before removal\n",
    "duplicates_before = final_encoded_data['id'].duplicated().sum()\n",
    "#print(f\"Number of duplicate IDs before handling: {duplicates_before}\")\n",
    "\n",
    "# Remove duplicate rows based on the 'id' column, keeping the first occurrence\n",
    "final_encoded_data = final_encoded_data[~final_encoded_data['id'].duplicated(keep='first')]\n",
    "\n",
    "# Check for duplicate IDs after removal\n",
    "duplicates_after = final_encoded_data['id'].duplicated().sum()\n",
    "#print(f\"Number of duplicate IDs after handling: {duplicates_after}\")\n",
    "\n",
    "# Display the decrease in duplicates\n",
    "duplicates_removed = duplicates_before - duplicates_after\n",
    "#print(f\"Number of duplicates removed: {duplicates_removed}\")\n",
    "\n",
    "# Encode date features\n",
    "final_encoded_data['year'] = pd.to_datetime(final_encoded_data['date']).dt.year\n",
    "final_encoded_data['month'] = pd.to_datetime(final_encoded_data['date']).dt.month\n",
    "final_encoded_data['day'] = pd.to_datetime(final_encoded_data['date']).dt.day\n",
    "final_encoded_data['day_of_week'] = pd.to_datetime(final_encoded_data['date']).dt.dayofweek  # 0=Monday, 6=Sunday\n",
    "final_encoded_data['is_weekend'] = final_encoded_data['day_of_week'].isin([5, 6]).astype(int)  # 1 if Saturday or Sunday\n",
    "\n",
    "# Drop the original 'date' column\n",
    "final_encoded_data.drop(columns=['date'], inplace=True)\n",
    "\n",
    "# Display the updated dataset\n",
    "print(\"Updated DataFrame after encoding and dropping 'date':\")\n",
    "display(final_encoded_data)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Separate training and test datasets\n",
    "train_data = final_encoded_data[final_encoded_data['sales'].notna()]  # Rows with non-NaN sales values\n",
    "test_data = final_encoded_data[final_encoded_data['sales'].isna()]    # Rows with NaN sales values\n",
    "\n",
    "\n",
    "# Define features and target for training\n",
    "X = train_data.drop(columns=['sales', 'id'])  # Features\n",
    "y = train_data['sales']  # Target\n",
    "\n",
    "# Define features for testing\n",
    "X_test = test_data.drop(columns=['sales', 'id'])\n",
    "\n",
    "# Split the training data into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize and train the model\n",
    "model = XGBRegressor(objective='reg:squarederror', random_state=42, n_estimators=100)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the validation set\n",
    "y_val_pred = model.predict(X_val)\n",
    "\n",
    "# Evaluate the model using MAE\n",
    "mae = mean_absolute_error(y_val, y_val_pred)\n",
    "print(f\"Validation MAE: {mae}\")\n",
    "\n",
    "# Predict sales on the test dataset\n",
    "test_data['sales'] = model.predict(X_test)\n",
    "\n",
    "# Prepare the submission file\n",
    "submission = test_data[['id', 'sales']].sort_values(by='id').reset_index(drop=True)\n",
    "submission.to_csv('/kaggle/working/submission.csv', index=False)\n",
    "\n",
    "# Display the first few rows of the submission file\n",
    "print(\"Submission file preview:\")\n",
    "display(submission)\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 2887556,
     "sourceId": 29781,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30786,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 46.634655,
   "end_time": "2024-11-21T15:21:28.220778",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-11-21T15:20:41.586123",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
